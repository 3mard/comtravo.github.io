<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"> <!-- Begin Jekyll SEO tag v2.5.0 --><title>Named Entity Recognition using Neural Networks | Comtravo tech</title><meta name="generator" content="Jekyll v3.8.5" /><meta property="og:title" content="Named Entity Recognition using Neural Networks" /><meta name="author" content="Comtravo" /><meta property="og:locale" content="en_US" /><meta name="description" content="Review of recent neural network methods for named-entity recognition." /><meta property="og:description" content="Review of recent neural network methods for named-entity recognition." /><link rel="canonical" href="http://localhost:4000/Neural-NER-Systems/" /><meta property="og:url" content="http://localhost:4000/Neural-NER-Systems/" /><meta property="og:site_name" content="Comtravo tech" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2019-01-02T15:12:00+01:00" /> <script type="application/ld+json"> {"description":"Review of recent neural network methods for named-entity recognition.","author":{"@type":"Person","name":"Comtravo"},"@type":"BlogPosting","url":"http://localhost:4000/Neural-NER-Systems/","headline":"Named Entity Recognition using Neural Networks","dateModified":"2019-01-02T15:12:00+01:00","datePublished":"2019-01-02T15:12:00+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/Neural-NER-Systems/"},"@context":"http://schema.org"}</script> <!-- End Jekyll SEO tag --><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/icons/apple-touch-icon.png?v=qA3OXqyw77"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/icons/favicon-32x32.png?v=qA3OXqyw77"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/icons/favicon-16x16.png?v=qA3OXqyw77"><link rel="manifest" href="/assets/img/icons/manifest.json?v=qA3OXqyw77"><link rel="mask-icon" href="/assets/img/icons/safari-pinned-tab.svg?v=qA3OXqyw77" color="#5bbad5"> <!--[if IE]><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><![endif]--><link rel="shortcut icon" href="/assets/img/icons/favicon.ico?v=qA3OXqyw77"><meta name="apple-mobile-web-app-title" content="Sleek"><meta name="application-name" content="Sleek"><meta name="msapplication-config" content="/assets/img/icons/browserconfig.xml?v=qA3OXqyw77"><meta name="theme-color" content="#ffffff"><style class="inlineCSS"> h1{color:#313237;margin-top:0;margin-bottom:.5rem}.dark-bg{background-color:#313237}@media only screen and (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:last-of-type,.post-card:nth-child(2n+2){margin-right:0}}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}header,nav,section{display:block}h1{font-size:2em;margin:.67em 0}figure,main{display:block}figure{margin:1em 40px}a{background-color:transparent;-webkit-text-decoration-skip:objects}img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}body{-webkit-overflow-scrolling:touch}*,::after,::before{-webkit-box-sizing:inherit;box-sizing:inherit}.site{display:-webkit-box;display:-ms-flexbox;display:flex;min-height:100vh;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.site__content{-webkit-box-flex:1;-ms-flex:1;flex:1}img{max-width:100%;height:auto;width:auto;vertical-align:middle}figure{margin:0}body{background-color:#fff;font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Hiragino Sans GB","Microsoft YaHei","WenQuanYi Micro Hei",sans-serif;font-size:1rem;line-height:1.5;color:#343851;-webkit-font-smoothing:antialiased;-webkit-text-size-adjust:100%}p{margin-top:0;margin-bottom:1.25rem}h1,h2{color:#313237;margin-top:0;margin-bottom:.5rem}a{color:#277cea;text-decoration:none;border-bottom:1px dashed #277cea}.blur{background:#fff;filter:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg"><filter id="filter"><feGaussianBlur stdDeviation="16" /></filter></svg>#filter');-webkit-filter:blur(1rem);filter:blur(1rem)}.container{padding:0 20px;max-width:100%;margin:0 auto}@media only screen and (min-width:36em){.container{max-width:540px;margin:0 auto}}@media only screen and (min-width:48em){.container{max-width:720px;margin:0 auto}}@media only screen and (min-width:62em){.container{max-width:960px;margin:0 auto}}@media only screen and (min-width:75em){.container{max-width:1170px;margin:0 auto}}.header{background-color:#fff;color:#343851;position:absolute;z-index:4;width:100%;top:0;left:0;will-change:transform;-webkit-transform:translateY(0);transform:translateY(0)}.header a{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-bottom:0}.header__logo{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;overflow:hidden;padding:19px 0;margin-right:1.25rem;outline:0;border-bottom:0;color:#313237}.header__logo .header__logo--container{width:58px}.header__logo .header__logo--container .logo{fill:currentColor}.header__inner{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:3.75em;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.header__links{padding-bottom:.5rem;display:none;position:absolute;top:3.75em;left:0;width:100%;height:auto;background:#fff}.header__link{color:#343851;padding:.938rem 0;border-top:1px solid #ededed}.header__toggle{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:44px;height:100%;background-color:transparent;padding-left:1.25rem}.header__toggle span{display:block;position:relative;margin-top:4px;background-color:#343851;width:100%;height:2px;border-radius:1px}.header__toggle span:first-child{margin-top:0}@media (min-width:62em){.header__toggle{display:none;visibility:hidden}.header__links{position:static;padding:0;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;visibility:visible;width:auto;height:100%}.header__links-wrapper{display:-webkit-box;display:-ms-flexbox;display:flex;height:100%;padding:0}.header__link{position:relative;padding:.938rem 1rem;border:0;height:100%}.header__link::after{content:"";display:block;position:absolute;left:0;bottom:0;height:3px;width:100%;-webkit-transform:scaleX(0);transform:scaleX(0);background:#277cea}}.post-card{display:block;position:relative;width:100%;min-height:250px;border-radius:4px;overflow:hidden;background-color:#fff;-webkit-box-shadow:0 1px 3px rgba(0,0,0,.08);box-shadow:0 1px 3px rgba(0,0,0,.08);margin-bottom:2.25rem;border-bottom:0}@media only screen and (min-width:48em){.post-card{width:48.4375%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:0}}@media only screen and (min-width:75em){.post-card{width:31.25%;margin-right:3.125%}.post-card:nth-child(2n+2){margin-right:3.125%}}.post-card__label{position:absolute;top:1.5rem;left:1.5rem;z-index:2}.post-card__inner{display:block;position:relative;padding:1.875rem 1.25rem .625rem;width:100%;color:#838c8d;border-bottom:0}.post-card__header{margin-bottom:.75rem}.post-card__meta{font-size:.875rem}.post-card__thumb{margin:0;background:#fff;position:relative;overflow:hidden}.post-card__thumb::after{content:"";display:block;height:0;width:100%;padding-bottom:56.25%}.post-card__thumb>*{position:absolute;top:0;left:0;width:100%;height:100%;display:block}.label{padding:0 10px;margin-bottom:1rem;display:inline-block;line-height:20px;font-size:.75rem;text-transform:uppercase;letter-spacing:1px;color:rgba(255,255,255,.8);border:2px solid rgba(255,255,255,.5);border-radius:100px}.hero{margin:3.75rem auto 0;min-height:16.25rem;width:100%;position:relative;background-color:#dde5ea;background-repeat:no-repeat;background-position:50%;background-size:cover}@media only screen and (min-width:62em){.hero{margin:0 auto;height:36em}}.hero::before{position:absolute;display:block;content:"";top:0;left:0;width:100%;height:100%;background:rgba(52,56,81,.8)}.hero__wrap{position:absolute;margin:auto;top:50%;left:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);text-align:center;color:rgba(255,255,255,.8);width:100%;max-width:90%;z-index:1}.hero__wrap .hero__title{font-size:1.8em;color:#fff}.blog{background-color:#f9f9f9}.post-list{padding-top:2.5em;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-flex:1;-ms-flex:1 0 auto;flex:1 0 auto}@media only screen and (min-width:48em){.hero__wrap{max-width:40em}.hero__wrap .hero__title{padding:1rem 0;font-size:2.625em;line-height:3.125rem}.post-list{padding-top:5em}}</style><link rel="preload" href="/assets/css/main.css" as="style" onload="this.rel='stylesheet'"> <noscript><link rel="stylesheet" href="/assets/css/main.css"></noscript> <script type="text/javascript"> /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */ (function(w){"use strict";if(!w.loadCSS){w.loadCSS=function(){}} var rp=loadCSS.relpreload={};rp.support=(function(){var ret;try{ret=w.document.createElement("link").relList.supports("preload")}catch(e){ret=!1} return function(){return ret}})();rp.bindMediaToggle=function(link){var finalMedia=link.media||"all";function enableStylesheet(){link.media=finalMedia} if(link.addEventListener){link.addEventListener("load",enableStylesheet)}else if(link.attachEvent){link.attachEvent("onload",enableStylesheet)} setTimeout(function(){link.rel="stylesheet";link.media="only x"});setTimeout(enableStylesheet,3000)};rp.poly=function(){if(rp.support()){return} var links=w.document.getElementsByTagName("link");for(var i=0;i<links.length;i++){var link=links[i];if(link.rel==="preload"&&link.getAttribute("as")==="style"&&!link.getAttribute("data-loadcss")){link.setAttribute("data-loadcss",!0);rp.bindMediaToggle(link)}}};if(!rp.support()){rp.poly();var run=w.setInterval(rp.poly,500);if(w.addEventListener){w.addEventListener("load",function(){rp.poly();w.clearInterval(run)})}else if(w.attachEvent){w.attachEvent("onload",function(){rp.poly();w.clearInterval(run)})}} if(typeof exports!=="undefined"){exports.loadCSS=loadCSS} else{w.loadCSS=loadCSS}}(typeof global!=="undefined"?global:this)) </script></head><body class="site"><header class="header" itemscope itemtype="http://schema.org/SiteNavigationElement" aria-label="Main navigation"><div class="container"><div class="header__inner"> <a class="header__logo" href="/"><div class="header__logo--container"> <?xml version="1.0" encoding="UTF-8"?> <svg width="38px" height="38px" viewBox="0 0 38 38" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"> <!-- Generator: Sketch 52.5 (67469) - http://www.bohemiancoding.com/sketch --><title>ComtravoLogo_square</title><desc>Created with Sketch.</desc> <g id="ComtravoLogo_square" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M35.6620561,4.04661309 L1.79462751,6.10975594 C1.07891322,6.15347023 0.740341792,7.00718452 1.23148465,7.53004166 L11.6894846,18.7020417 C11.9577704,18.9883274 12.3863418,19.0560417 12.7274846,18.8648988 L27.4540561,10.6166131 C27.8620561,10.3877559 28.0051989,9.87261309 27.7746275,9.46461309 C27.5431989,9.05661309 27.0254846,8.9108988 26.6174846,9.1388988 L12.4711989,17.0614702 L3.69748465,7.69032737 L34.5066275,5.81318452 L18.5166275,30.5074702 L18.0417704,19.9226131 C18.0203418,19.4537559 17.6329132,19.0911845 17.1769132,19.1126131 C16.7200561,19.1340417 16.3669132,19.5317559 16.3883418,20.0006131 L16.9797704,33.1783274 C17.0166275,33.9986131 18.0520561,34.2943274 18.4951989,33.6103274 L36.8200561,5.31175594 C37.0729132,4.9208988 36.9700561,4.39375594 36.5894846,4.13318452 C36.3520561,3.97118452 35.7186275,4.04318452 35.6620561,4.04661309 Z" id="Fill-1" fill="#00B4EA" transform="translate(18.979293, 19.009207) rotate(2.000000) translate(-18.979293, -19.009207) "></path> </g> </svg></div></a><nav class="header__links"><div class="container header__links-wrapper"> <a class="header__link" href="/" itemprop="url"> <span itemprop="name">Home</span> </a></div></nav><div class="header__toggle"> <span></span> <span></span> <span></span></div></div></div></header><div class="hero dark-bg"><div class="hero__wrap"><div class="hero__categories"> <a class="label" href="//categories/#NER">NER</a> &nbsp; <a class="label" href="//categories/#Neural Networks">Neural Networks</a> &nbsp; <a class="label" href="//categories/#NLP">NLP</a> &nbsp; <a class="label" href="//categories/#Deep Learning">Deep Learning</a></div><h1 class="hero__title">Named Entity Recognition using Neural Networks</h1><p class="hero__meta"> <span> <time>02 Jan 2019</time>&nbsp;&middot; </span> <span> ~ 20 mins read </span></p><p class="hero__meta">David Batista - Research Engineer NLP</p></div></div><main class="site__content"><div class="container"><article class="post-content" itemprop="articleBody"><p>Recently (i.e., at the time of this writing since 2015~2016 onwards) new methods to perform sequence labelling tasks based on neural networks started to be proposed/published, I will try in this blog post to do a quick recap of some of these new methods, understanding their architectures and pointing out what each technique brought new or different to the already knew methods.</p><h1 id="introduction"><strong>Introduction</strong></h1><p>Several NLP tasks involve classifying a sequence, a classical example is part-of-speech tagging, in this scenario, each <script type="math/tex">x_{i}</script> describes a word and each <script type="math/tex">y_{i}</script> the associated part-of-speech of the word <script type="math/tex">x_{i}</script> (e.g.: <em>noun</em>, <em>verb</em>, <em>adjective</em>, etc.).</p><p>Another example, is named-entity recognition, in which, again, each <script type="math/tex">x_{i}</script> describes a word and <script type="math/tex">y_{i}</script> is a semantic label associated to that word (e.g.: <em>person</em>, <em>location</em>, <em>organization</em>, <em>event</em>, etc.).</p><h1 id="linear-sequence-models"><strong>Linear Sequence Models</strong></h1><p>Classical approaches (i.e., prior to the neural networks revolution in NLP) to deal with these tasks involved methods which made independent assumptions, that is, the tag decision for each word depends only on the surrounding words and not on previous classified words.</p><p>Then methods that take into consideration the sequence structure i.e., the tag given to the previous classified word(s) is considered when deciding the tag to give to the following word.</p><p>You can read more about these last methods here:</p><ul><li><p><strong><a href="../../../../../blog/2017/11/11/HHM_and_Naive_Bayes/">Hidden Markov Model and Naive Bayes relationship</a></strong></p></li><li><p><strong><a href="http://www.davidsbatista.net/blog/2017/11/12/Maximum_Entropy_Markov_Model/">Maximum Entropy Markov Models and Logistic Regression</a></strong></p></li><li><p><strong><a href="http://www.davidsbatista.net/blog/2017/11/13/Conditional_Random_Fields/">Conditional Random Fields for Sequence Prediction</a></strong></p></li></ul><p>But recently, methods based on neural networks started succeed and are nowadays state-of-the-art in mostly NLP sequence prediction tasks.</p><p>Most of this methods combine not one simple neural network but several neural networks working in tandem, i.e., combining different architectures. One important architecture common to all recent methods is recurrent neural network (RNN).</p><p>A RNN introduces the connection between the previous hidden state and current hidden state, and therefore a recurrent layer weight parameters. This recurrent layer is designed to store history information. When reading through a sequence of words, the input and output layers have:</p><ul><li>Input layer:<ul><li>same dimensionality as feature size</li></ul></li><li>Output layer:<ul><li>represents a probability distribution over labels at time <script type="math/tex">t</script></li><li>same dimensionality as size of labels.</li></ul></li></ul><!--__TODO__: imagem de uma RNN--><p>However, in most proposed techniques, the RNN is replaced by a Long short-term memory (LSTM), where hidden layer updates are replaced by purpose-built memory cells. As a result, they may be better at finding and exploiting long range dependencies in the data.</p><!--__TODO__: imagem de uma LSTM, e uma curta descrição--> <!-- Basically, a LSTM unit is composed of three multiplicative gates which control the proportions of information to forget and to pass on to the next time step. --><p>Another architecture that is combined with LSTMs in the works described in this post is <strong><a href="http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/">Convolutional Neural Networks</a></strong>.</p><h1 id="neural-sequence-labelling-models"><strong>Neural Sequence Labelling Models</strong></h1><p>The first ever work to try to use try to LSTMs for the task of Named Entity Recognition was published back in 2003:</p><ul><li><a href="http://www.aclweb.org/anthology/W03-0426">Named Entity Recognition with Long Short-Term Memory (James Hammerton 2003)</a></li></ul><p>but lack of computational power led to small and not expressive enough models, consequently with performance results far behind other proposed methods at that time.</p><p>I will describe four recent papers which propose neural network architectures to perform NLP sequence labelling tasks such as NER, chunking, or POS-tagging, I will focus only on the architectures proposed and detailed them, and leave out of the datasets or scores</p><ul><li><p><a href="https://arxiv.org/pdf/1508.01991v1.pdf">Bidirectional LSTM-CRF Models for Sequence Tagging (Huang et. al 2015)</a></p></li><li><p><a href="https://www.aclweb.org/anthology/Q16-1026">Named Entity Recognition with Bidirectional LSTM-CNNs (Chiu and Nichols 2016)</a></p></li><li><p><a href="http://www.aclweb.org/anthology/N16-1030">Neural Architectures for Named Entity Recognition (Lample et. al 2016)</a></p></li><li><p><a href="http://www.aclweb.org/anthology/P16-1101">End-to-end Sequence Labelling via Bi-directional LSTM-CNNs-CRF (Ma and Hovy 2016)</a></p></li></ul><p>At time of writing there are already new proposed methods, published in 2017 and 2018, which are currently the state-of-the-art, but I will leave these for another blog post, for now I just wanted to dissect and understand something from the ones listed above :-)</p><hr /><p><br /></p><h3 id="bidirectional-lstm-crf-models-for-sequence-tagging-2015"><a href="https://arxiv.org/pdf/1508.01991v1.pdf">Bidirectional LSTM-CRF Models for Sequence Tagging (2015)</a></h3><h3 id="architecture"><strong>Architecture</strong></h3><p>This was, to the best of my knowledge, the first work to apply a bidirectional-LSTM-CRF architecture for sequence tagging. The idea is to use two LSTMs, one reading each word in a sentence from beginning to end and another reading the same but from end to beginning, producing for each word, a vector representation made from both the un-folded LSTM (i.e., forward and backward) read up to that word. There is this intuition that the vector for each word will take into account the words read/seen before, on both directions.</p><p>There is no explicit mention in the paper on how the vectors from each LSTM are combined to produce a single vector for each word, I will assume that they are just concatenated.</p><p>This bidirectional-LSTM architecture is then combined with a CRF layer at the top. A Conditional Random Field (CRF) layer has a state transition matrix as parameters, which can be used to efficiently use past attributed tags in predicting the current tag.</p><figure> <img style="width: 55%; height: 55%" src="/assets/img/2019_01_22/2019-01-22_A_bi-LSTM-CRF_model.png" /><figcaption><b>A bi-LSTM-CRF model for NER.</b> <br />(Image taken from Huang et. al 2015)</figcaption></figure><p><br /></p><h3 id="features-and-embeddings"><strong>Features and Embeddings</strong></h3><p>Word embeddings, generate from each state of the LSTM, are combined with hand-crafted features:</p><ul><li>spelling, e.g.: capitalization, punctuation, word patters, etc.</li><li>context, e.g: uni-, bi- and tri-gram features</li></ul><p>The embeddings used are those produced by <a href="http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf">Collobert et al., 2011</a> which has 130K vocabulary size and each word corresponds to a 50-dimensional embedding vector.</p><p><strong>Features connection tricks</strong>:</p><p>The input for the model include both word, spelling and context features, however, the authors suggest direct connecting the hand-crafted features to the output layer (i.e, CRF) which accelerates training and result in very similar tagging accuracy, when comparing without direct connections. That is, in my understanding, the vector representing the hand-crafted features are passed directly to the CRF and are not passed through the bidirectional-LSTM</p><figure> <img style="width: 55%; height: 55%" src="/assets/img/2019_01_22/2019-01-22_A_bi-LSTM-CRF_model_with_max_ent_features.png" /><figcaption><b>A bi-LSTM-CRF model with Maximum Entropy features.</b> <br />(Image taken from Huang et. al 2015)</figcaption></figure><h2 id="summary"><strong>Summary</strong></h2><p>In essence, I guess one can see this architecture as using the output of the bidirectional-LSTM, vector representations for each word in a sentence, together with a vector of features derived from spelling and context hand-crafted rules, these vectors are concatenated and passed to a CRF layer.</p><hr /><h4 id="named-entity-recognition-with-bidirectional-lstm-cnns-2016"><a href="https://www.aclweb.org/anthology/Q16-1026">Named Entity Recognition with Bidirectional LSTM-CNNs (2016)</a></h4><h3 id="architecture-1"><strong>Architecture</strong></h3><p>The authors propose a hybrid model combining bidirectional-LSTMs with a Convolutional Neural Network (CNN), the latter learns both character- and word-level features. So, this makes use of words-embeddings, additional hand-crafted word features, and CNN-extracted character-level features. All these features, for each word, are fed into a bidirectional-LSTM.</p><figure> <img style="width: 42.5%; height: 42.5%" src="/assets/img/2019_01_22/2019-01-22-CNN-Char-Embeddings.png" /><figcaption><b>A bidirectional-LSTMs with CNNs.</b> <br />(Image taken from Chiu and Nichols 2016)</figcaption></figure><p>The output vector of each LSTM (i.e., forward and backward) at each time step is decoded by a linear layer and a log-softmax layer into log-probabilities for each tag category, and These two vectors are then added together.</p><figure> <img style="width: 35%; height: 45%" src="/assets/img/2019_01_22/2019-01-22-output_layer.png" /><figcaption><b>Output Layer.</b> <br />(Image taken from Chiu and Nichols 2016)</figcaption></figure><p><br /></p><p>Character-level features are induced by a CNN architecture, which was successfully applied to Spanish and Portuguese NER <a href="http://www.anthology.aclweb.org/W/W15/W15-3904.pdf">(Santos et al., 2015)</a> and German POS-tagging <a href="http://www.aclweb.org/anthology/D15-1025">(Labeau et al., 2015)</a>. For each word a convolution and a max layer are applied to extract a new feature vector from the per-character feature vectors such as character embeddings and character type.</p><figure> <img style="width: 42.5%; height: 42.5%" src="/assets/img/2019_01_22/2019-01-22-bi-directional-LSTM-with-CNN-chars.png" /><figcaption><b>Char-Embeddings architecture.</b> <br />(Image taken from Chiu and Nichols 2016)</figcaption></figure><p><br /></p><h3 id="features-and-embeddings-1"><strong>Features and Embeddings</strong></h3><p><strong>Word Embeddings</strong>: 50-dimensional word embeddings <a href="http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf">(Collobert et al. 2011)</a>, all words are lower-cased, embeddings are allowed to be modified during training.</p><p><strong>Character Embeddings</strong>: randomly initialized a lookup table with values drawn from a uniform distribution with range [−0.5,0.5] to output a character embedding of 25 dimensions. Two special tokens are added: PADDING and UNKNOWN.</p><p><strong>Additional Char Features</strong> A lookup table was used to output a 4-dimensional vector representing the type of the character (<em>upper case</em>, <em>lower case</em>, <em>punctuation</em>, <em>other</em>).</p><p><strong>Additional Word Features</strong>: each words is tagged as <em>allCaps</em>, <em>upperInitial</em>, <em>lowercase</em>, <em>mixedCaps</em>, <em>noinfo</em>.</p><p><strong>Lexicons</strong>: partial lexicon matches using a list of known named-entities from DBpedia. The list is then used to perform $n$-gram matches against the words. A match is successful when the $n$-gram matches the prefix or suffix of an entry and is at least half the length of the entry.</p><p><br /></p><h2 id="summary-1"><strong>Summary</strong></h2><p>The authors also explore several features, some hand-crafted:</p><ul><li>word embeddings</li><li>word shape features</li><li>character-level features (extracted with a CNN)</li><li>lexical features</li></ul><p>All these features are then concatenated, passed through a bi-LSTM and each time step is decoded by a linear layer and a log-softmax layer into log-probabilities for each tag category. The model also learns a tag transition matrix, and at inference time the Viterbi algorithm selects the sequence that maximizes the score all possible tag-sequences.</p><h2 id="implementations"><strong>Implementations</strong></h2><ul><li><a href="https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs">https://github.com/kamalkraj/Named-Entity-Recognition-with-Bidirectional-LSTM-CNNs</a></li></ul><hr /><p><br /></p><h3 id="neural-architectures-for-named-entity-recognition-2016"><a href="http://www.aclweb.org/anthology/N16-1030">Neural Architectures for Named Entity Recognition (2016)</a></h3><h3 id="architecture-2"><strong>Architecture</strong></h3><p>This was, to the best of my knowledge, the first work on NER to completely drop hand-crafted features, i.e., they use no language-specific resources or features beyond a small amount of supervised training data and unlabeled corpora.</p><p>Two architectures are proposed:</p><ul><li>bidirectional LSTMs + Conditional Random Fields (CRF)</li><li>generating labels segments using a transition-based approach inspired by shift-reduce parsers</li></ul><p>I will just focus on the first model, which follows a similar architecture as the other models presented in this post. I personally like this model mostly because of it’s simplicity.</p><p>As in the previous models, two LSTMs are used to generate a word representation by concatenating its left and right context. These are two distinct LSTMs with different parameters. The tagging decisions are modeled jointly using a CRF layer <a href="https://repository.upenn.edu/cgi/viewcontent.cgi?article=116">(Lafferty et al., 2001)</a>.</p><figure> <img style="width: 42.5%; height: 42.5%" src="/assets/img/2019_01_22/2019-01-22-neural-arch.png" /><figcaption><b>Model Architecture.</b> <br />(Image taken from Lample et. al 2016)</figcaption></figure><h3 id="embeddings"><strong>Embeddings</strong></h3><p>The authors generate words embeddings from both representations of the characters of the word and from the contexts where the word occurs.</p><p>The rational behinds this idea is that many languages have orthographic or morphological evidence that a word or sequence of words is a named-entity or not, so they use character-level embeddings to try to capture these evidences. Secondly, named-entities appear in somewhat regular contexts in large corpora, therefore they use embeddings learned from a large corpus that are sensitive to word order.</p><h4 id="character-embeddings"><strong>Character Embeddings</strong></h4><figure> <img style="width: 42.5%; height: 42.5%" src="/assets/img/2019_01_22/2019-01-22-nerual-arch-char-embeddings.png" /><figcaption><b>Character-Embeddings Architecture.</b> <br />(Image taken from Lample et. al 2016)</figcaption></figure><p>A character lookup table is initialized randomly containing an embedding for every character. The character embeddings corresponding to every character in a word are given in direct and reverse order to a bidirectional-LSTM. The embedding for a word derived from its characters is the concatenation of its forward and backward representations from the bidirectional-LSTM. The hidden dimension of the forward and backward character LSTMs are 25 each.</p><h4 id="word-embeddings"><strong>Word Embeddings</strong></h4><p>This character-level representation is then concatenated with a word-level representation from pre-trained word embeddings. Embeddings are pre-trained using skip-n-gram <a href="http://www.aclweb.org/anthology/D15-1161">(Ling et al., 2015)</a>, a variation of skip-gram that accounts for word order.</p><p>These embeddings are fine-tuned during training, and the authors claim that using pre-trained over randomly initialized ones results in performance improvements.</p><p>They also mention that they apply a dropout mask to the final embedding layer just before the input to the bidirectional LSTM observe a significant improvement in model’s performance after using dropout.</p><h2 id="summary-2"><strong>Summary</strong></h2><p>This model is relatively simple, the authors use no hand-crafted features, just embeddings. The word embeddings are the concatenation of two vectors, a vector made of character embeddings using two LSTMs, for each character in a word, and a vector corresponding to word embeddings trained on external data.</p><p>The embeddings for word each word in a sentence are then passed through a forward and backward LSTM, and the output for each word is then fed into a CRF layer.</p><h2 id="implementations-1"><strong>Implementations</strong></h2><ul><li><a href="https://github.com/glample/tagger">https://github.com/glample/tagger</a></li><li><a href="https://github.com/Hironsan/anago">https://github.com/Hironsan/anago</a></li><li><a href="https://github.com/achernodub/bilstm-cnn-crf-tagger">https://github.com/achernodub/bilstm-cnn-crf-tagger</a></li></ul><hr /><p><br /></p><h4 id="end-to-end-sequence-labelling-via-bi-directional-lstm-cnns-crf-2016"><a href="http://www.aclweb.org/anthology/P16-1101">End-to-end Sequence Labelling via Bi-directional LSTM-CNNs-CRF (2016)</a></h4><h3 id="architecture-3"><strong>Architecture</strong></h3><p>This system is very similar to the previous one. The authors use a Convolutional Neural Networks (CNN) to encode character-level information of a word into its character-level representation. Then combine character- and word-level representations and feed them into bidirectional LSTM to model context information of each word. Finally, the output vectors of BLSTM are fed to the CRF layer to jointly decode the best label sequence.</p><figure> <img style="width: 42.5%; height: 42.5%" src="/assets/img/2019_01_22/2019-01-22_end_to_ent2.png" /><figcaption><b>Model Architecture.</b> <br />(Image taken from Ma and Hovy 2016)</figcaption></figure><h3 id="embeddings-1"><strong>Embeddings</strong></h3><h4 id="character-embeddings-1"><strong>Character Embeddings</strong></h4><p>The CNN is similar to the one in <a href="https://www.aclweb.org/anthology/Q16-1026">Chiu and Nichols (2015)</a>, the second system presented, except that they use only character embeddings as the inputs to CNN, without any character type features. A dropout layer is applied before character embeddings are input to CNN.</p><figure> <img style="width: 42.5%; height: 42.5%" src="/assets/img/2019_01_22/2019-01-22_end_to_ent1.png" /><figcaption><b>Character-embeddings Architecture.</b> <br />(Image taken from Ma and Hovy 2016)</figcaption></figure><h4 id="word-embeddings-1"><strong>Word Embeddings</strong></h4><p>The word embeddings are the publicly available GloVe 100-dimensional embeddings trained on 6 billion words from Wikipedia and web text.</p><h2 id="summary-3"><strong>Summary</strong></h2><p>This model follows basically the same architecture as the one presented before, being the only architecture change the fact that they use CNN to generate word-level char-embeddings instead of an LSTM.</p><h2 id="implementations-2"><strong>Implementations</strong></h2><ul><li><a href="https://github.com/achernodub/bilstm-cnn-crf-tagger">https://github.com/achernodub/bilstm-cnn-crf-tagger</a></li></ul><hr /><p><br /></p><h2 id="comparative-summary"><strong>Comparative Summary</strong></h2><p>I would say the main lessons learned from reading these papers are:</p><ul><li>Use two LSTMs (forward and backward)</li><li>CRF on the top/final layer to model tag transitions</li><li>Final embeddings are a combinations of word- and character embeddings</li></ul><p>In the following table I try to summarize the main characteristics of each of the models</p><table class="blueTable"><thead><tr><th>&nbsp;</th><th>Features</th><th>Architecture Resume</th><th>Structured Tagging</th><th>Embeddings</th></tr></thead><tbody><tr><td>(Huang et. al 2015)</td><td>Yes</td><td> bi-LSTM output vectors + <br /> features vectors connected to CRF</td><td>CRF</td><td>Collobert et al. 2011 <br /> pre-trained <br /> 50-dimensions</td></tr><tr><td>(Chiu and Nichols 2016)</td><td>Yes</td><td> word embeddings + features vector <br /> input to a bi-LSTM the output <br /> at each time step is decoded by a <br /> linear layer and a log-softmax layer <br /> into log-probabilities for each tag category <br /></td><td> Sentence-level log-likelihood</td><td> - Collobert et al. 2011 <br /> - char-level embeddings <br /> extracted with a CNN</td></tr><tr><td>(Lample et. al 2016)</td><td>No</td><td> chars and word embeddings <br /> input for the bi-LSTM <br /> output vectors are fed to the CRF layer to jointly decode the best label sequence</td><td>CRF</td><td> - char-level embeddings <br /> extracted with a bi-LSTM <br /> - pre-trained word embeddings <br /> with skip-n-gram</td></tr><tr><td>(Ma and Hovy 2016)</td><td>No</td><td> chars and word embeddings <br /> input for the bi-LSTM <br /> output vectors are fed to the CRF layer to jointly decode the best label sequence</td><td>CRF</td><td> - char embeddings extracted with a CNN <br /> - word embeddings: GloVe 100-dimensions</td></tr></tbody></table><hr /><h2 id="references"><strong>References</strong></h2><!-- https://www.lewuathe.com/machine%20learning/crf/conditional-random-field.html --><ul><li><p><a href="https://arxiv.org/pdf/1508.01991v1.pdf">Bidirectional LSTM-CRF Models for Sequence Tagging (Huang et. al 2015)</a></p></li><li><p><a href="https://www.aclweb.org/anthology/Q16-1026">Named Entity Recognition with Bidirectional LSTM-CNNs (Chiu and Nichols 2016)</a></p></li><li><p><a href="https://www.aclweb.org/anthology/N16-1030">Neural Architectures for Named Entity Recognition (Lample et. al 2016)</a></p></li><li><p><a href="http://www.aclweb.org/anthology/P16-1101">End-to-end Sequence Labelling via Bi-directional LSTM-CNNs-CRF (Ma and Hovy 2016)</a></p></li><li><p><a href="https://www.robots.ox.ac.uk/~vgg/rg/papers/hmm.pdf">A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition</a></p></li><li><p><a href="https://www.youtube.com/watch?v=6dpGB60Q1Ts">Hugo Larochelle on-line lessons - Neural networks [4.1] : Training CRFs - loss function</a></p></li><li><p><a href="https://createmomo.github.io/">Blog article: CRF Layer on the Top of BiLSTM - 1 to 8</a></p></li><li><p><a href="http://www.aclweb.org/anthology/D15-1161">Not All Contexts Are Created Equal: Better Word Representations with Variable Attention (Ling et al., 2015)</a></p></li><li><p><a href="http://www.aclweb.org/anthology/D15-1025">Non-lexical neural architecture for fine-grained POS Tagging (Labeau et al., 2015)</a></p></li><li><p><a href="http://www.anthology.aclweb.org/W/W15/W15-3904.pdf">Boosting Named Entity Recognition with Neural Character Embeddings (Santos et al., 2015)</a></p></li><li><p><a href="http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf">Natural Language Processing (Almost) from Scratch (2011)</a></p></li></ul><hr /><p><br /><br /></p><h3 id="extra-why-a-conditional-random-field-at-the-top"><strong>Extra: Why a Conditional Random Field at the top?</strong></h3><p>Having independent classification decisions is limiting when there are strong dependencies across output labels, since you decide the label for a word independently from the previous given tags.</p><p>For sequence labeling or general structured prediction tasks, it is beneficial to consider the correlations between labels in neighborhoods and jointly decode the best chain of labels for a given input sentence:</p><ul><li><p>NER is one such task, since interpretable sequences of tags have constraints, e.g.: I-PER cannot follow B-LOC that would be impossible to model with independence assumptions;</p></li><li><p>Another example is in POS tagging, an adjective is more likely to be followed by a noun than a verb;</p></li></ul><p>The idea of using a CRF at the top is to model tagging decisions jointly, that is the probability of a given label to a word depends on the features associated to that word (i.e., final word embedding) and the assigned tag the word before.</p><p>This means that the CRF layer could add constrains to the final predicted labels ensuring they are valid. The constrains are learned by the CRF layer automatically based on the annotated samples during the training process.</p><h4 id="emission-score-matrix"><strong>Emission score matrix</strong></h4><p>The output of the LSTM is given as input to the CRF layer, that is, a matrix $\textrm{P}$ with the scores of the LSTM of size $n \times k$, where $n$ is the number of words in the sentence and $k$ is the possible number of labels that each word can have, $\textrm{P}_{i,j}$ is the score of the $j^{th}$ tag of the $i^{th}$ word in the sentence. In the image below the matrix would be the concatenation of the yellow blocks coming out of each LSTM.</p><figure> <img style="width: 50%; height: 50%" src="/assets/img/2019_01_22/2019-01-22_LSTM_CRF_matrix.png" /><figcaption><b>CRF Input Matrix</b> <br />(Image taken from https://createmomo.github.io/)</figcaption></figure><h4 id="transition-matrix"><strong>Transition matrix</strong></h4><p><script type="math/tex">\textrm{T}</script> is a matrix of transition scores such that <script type="math/tex">\textrm{P}_{i,j}</script> represents the score of a transition from the tag <script type="math/tex">i</script> to tag <script type="math/tex">j</script>. Two extra tags are added, $y_{0}$ and $y_{n}$ are the <em>start</em> and <em>end</em> tags of a sentence, that we add to the set of possible tags, $\textrm{T}$ is therefore a square matrix of size $\textrm{k}+2$.</p><figure> <img style="width: 72.5%; height: 72.5%" src="/assets/img/2019_01_22/2019-01-22_transition_matrix.png" /><figcaption><b>CRF State Transition Matrix</b> <br />(Image taken from https://eli5.readthedocs.io sklearn tutorial)</figcaption></figure><h4 id="score-of-a-prediction"><strong>Score of a prediction</strong></h4><p>For a given sequence of predictions for a sequence of words <script type="math/tex">x</script>:</p><script type="math/tex; mode=display">\textrm{y} = (y_{1},y_{2},\dots,y_{n})</script><p>we can compute it’s score based on the <em>emission</em> and <em>transition</em> matrices:</p><script type="math/tex; mode=display">\textrm{score}(y) = \sum_{i=0}^{n} \textrm{T}_{y_i,y_{i+1}} + \sum_{i=1}^{n} \textrm{P}_{i,y_i}</script><p>so the score of a sequence of predictions is, for each word, the sum of the transition from the current assigned tag <script type="math/tex">y_i</script> to next assigned tag <script type="math/tex">y_{i+1}</script> plus the probability given by the LSTM to the tag assigned for the current word <script type="math/tex">i</script>.</p><h4 id="training-parameter-estimation"><strong>Training: parameter estimation</strong></h4><p>During training, we assign a probability to each tag but maximizing the probability of the correct tag <script type="math/tex">y</script> sequence among all the other possible tag sequences.</p><p>This is modeled by applying a softmax over all the possible taggings <script type="math/tex">y</script>:</p><script type="math/tex; mode=display">\textrm{p(y|X)} = \frac{e^{score(X,y)}}{\sum\limits_{y' \in Y({x})} e^{score(X,y')}}</script><p>where <script type="math/tex">Y(x)</script> denotes the set of all possible label sequences for <script type="math/tex">x</script>, this denominator is also known as the partition function. So, finding the best sequence is the equivalent of finding the sequence that maximizes <script type="math/tex">\textrm{score(X,y)}</script>.</p><p>The loss can be defined as the negative log likelihood of the current tagging <script type="math/tex">y</script>:</p><script type="math/tex; mode=display">\textrm{-log p}(y\textrm{|X)}</script><p>so, in simplifying the function above, a first step is to get rid of the fraction using log equivalences, and then get rid of the <script type="math/tex">\textrm{log}\ e</script> in the first term since they cancel each other out:</p><script type="math/tex; mode=display">\textrm{-log p}(y\textrm{|X)} = -\ \textrm{score(X,y)} + \textrm{log} \sum\limits_{y' \in Y({x})} \textrm{exp}(\textrm{score(X,y')})</script><p>then the second term can be simplified by applying the log-space addition <em>logadd</em>, equivalence, i.e.: <script type="math/tex">\oplus(a, b, c, d) = log(e^a+e^b+e^c+e^d)</script>:</p><script type="math/tex; mode=display">\textrm{-log p}(y\textrm{|X)} = -\ \textrm{score(X,y)} + \underset{y' \in Y({x})}{\text{logadd}} (\textrm{score(X,y')})</script><p>then, replacing the <script type="math/tex">\textrm{score}</script> by it’s definition:</p><script type="math/tex; mode=display">= - (\sum_{i=0}^{n} \textrm{T}_{y_i,y_{i+1}} + \sum_{i=1}^{n} \textrm{P}_{i,y_i}) + \underset{y' \in Y({x})}{\text{logadd}}(\sum_{i=0}^{n} \textrm{T}_{y'_i,y'_{i+1}} + \sum_{i=1}^{n} \textrm{P}_{i,y_i})</script><p>The first term is score for the true data. Computing the second term might be computationally expensive since it requires summing over the <script type="math/tex">k^{n}</script> different sequences in <script type="math/tex">Y(x)</script>, i.e., the set of all possible label sequences for <script type="math/tex">x</script>. This computation can be solved using a variant of the Viterbi algorithm, the forward algorithm.</p><p>The gradients are then computed using back-propagation, since the CRF is inside the neural-network. Note that the transition scores in the matrix are randomly initialized - or can also bee initialized based on some criteria, to speed up training - and will be updated automatically during your training process.</p><h4 id="inference-determining-the-most-likely-label-sequence-y-given-x"><strong>Inference: determining the most likely label sequence <script type="math/tex">y</script> given <script type="math/tex">X</script></strong></h4><p>Decoding is to search for the single label sequence with the largest joint probability conditioned on the input sequence:</p><script type="math/tex; mode=display">\underset{y}{\arg\max}\ \textrm{p(y|X;}\theta)</script><p>the parameters <script type="math/tex">\theta</script> correspond to the <em>transition</em> and <em>emission</em> matrices, basically the task is finding the best <script type="math/tex">\hat{y}</script> given the transition matrix <script type="math/tex">\textrm{T}</script> and the matrix <script type="math/tex">\textrm{P}</script> with scores for each tag for the individual word:</p><script type="math/tex; mode=display">\textrm{score} = \sum_{i=0}^{n} \textrm{T}_{y_i,y_{i+1}} + \sum_{i=1}^{n} \textrm{P}_{i,y_i}</script><p>a linear-chain sequence CRF model, models only interactions between two successive labels, i.e bi-gram interactions, therefore one can find the sequence <script type="math/tex">y</script> maximizing the <strong>score</strong> function above by adopting the Viterbi algorithm (Rabiner, 1989).</p></article><div class="post-content controls__inner"><div class="controls__item prev"></div><div class="controls__item next"> <span>Next</span> <a href="/AsyncRay/"> Async/Await and JavaScript ... <span> <svg xmlns="http://www.w3.org/2000/svg" width="6" height="11"><path fill="#fillColor" d="M.353 9.282c-.37.434-.323 1.09.106 1.465a1.016 1.016 0 0 0 1.446-.107L5.75 6.125a1.05 1.05 0 0 0-.017-1.378L1.784.34A1.015 1.015 0 0 0 .336.27a1.05 1.05 0 0 0-.07 1.468l3.34 3.725L.353 9.282z"/> </svg> </span> </a></div></div></div></main><footer class="footer"><div class="container"><nav class="social"> <a class="social__link" target="_blank" rel="noopener noreferrer" href="https://github.com/comtravo"> <svg class="social__icon" viewBox="0 0 20 20" width="20px" height="20px"><path d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg> </a> <a class="social__link" target="_blank" rel="noopener noreferrer" href="https://www.twitter.com/comtravo_travel"> <svg class="social__icon" viewBox="0 0 20 20" width="20px" height="20px"><path d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg> </a></nav><span>&copy; 2019 Comtravo tech. All rights reserved.</span></div></footer><script async src="/assets/js/bundle.js"></script> <script async> if ('serviceWorker' in navigator) { navigator.serviceWorker.register('/sw.js').then(function( registration ) { console.log('ServiceWorker registration successful with scope: ', registration.scope); }) .catch(function(error) { console.log('ServiceWorker registration failed: ', error); }); } </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script> <script type="text/javascript" charset="utf-8" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" > </script> <script type="text/javascript" charset="utf-8" src="https://vincenttam.github.io/javascripts/MathJaxLocal.js" > </script></body></html>
